{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load data...\"\"\"\n",
    "\n",
    "import load\n",
    "df = load.loadDF(1e11)\n",
    "\n",
    "#Slice required columns\n",
    "df_reviews = df[['reviewText','category']]\n",
    "\n",
    "category = df_reviews.category.unique()\n",
    "data = [[str(i) for i in df_reviews[df_reviews.category == cat]['reviewText']] for cat in category] \n",
    "\n",
    "len(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "n_features = 100000\n",
    "n_components = 10\n",
    "n_top_words = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 377 features extracted\n",
      "First 20 features extracted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '20',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'action',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'ago',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'aren',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'based',\n",
       " 'beat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"COUNT VECTORIZER FOR LDA\"\"\"\n",
    "ct_vectorizer = CountVectorizer(min_df=0.01,max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "ct_vectorizer.fit([i for j in data for i in j])\n",
    "\n",
    "ct = [ct_vectorizer.transform(i) for i in data]\n",
    "\n",
    "\n",
    "print('A total of %s features extracted' %(len(ct_vectorizer.get_feature_names())))\n",
    "print('First 20 features extracted:')\n",
    "ct_vectorizer.get_feature_names()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 412 features extracted\n",
      "First 20 features extracted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '20',\n",
       " 'abl',\n",
       " 'absolut',\n",
       " 'action',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'ago',\n",
       " 'allow',\n",
       " 'alreadi',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'ani',\n",
       " 'anoth',\n",
       " 'anyon',\n",
       " 'anyth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Stemmed vectroizer\"\"\"\n",
    "import multiprocessing as mp\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stemm_1item(it):\n",
    "    return ' '.join([stemmer.stem(word) for word in it.split(' ')])\n",
    "    \n",
    "#new_corpus=[stemm_1item(text) for text in data]\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    new_corpus = pool.map(stemm_1item, [i for j in data for i in j])\n",
    "\n",
    "ct_vectorizer.fit(new_corpus)\n",
    "\n",
    "ct = [ct_vectorizer.transform(i) for i in data]\n",
    "\n",
    "print('A total of %s features extracted' %(len(ct_vectorizer.get_feature_names())))\n",
    "print('First 20 features extracted:')\n",
    "ct_vectorizer.get_feature_names()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 375 features extracted\n",
      "First 20 features extracted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '20',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'action',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'ago',\n",
       " 'allow',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'aren',\n",
       " 'arrive',\n",
       " 'art',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'bad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Lemmatized Vectorizer\"\"\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer=WordNetLemmatizer()\n",
    "\n",
    "def lemm_1item(it):\n",
    "    return ' '.join([lemmer.lemmatize(word, pos = 'v') for word in it.split(' ')])\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    new_corpus = pool.map(lemm_1item, [i for j in data for i in j])\n",
    "\n",
    "ct_vectorizer.fit(new_corpus)\n",
    "\n",
    "ct = [ct_vectorizer.transform(i) for i in data]\n",
    "\n",
    "print('A total of %s features extracted' %(len(ct_vectorizer.get_feature_names())))\n",
    "print('First 20 features extracted:')\n",
    "ct_vectorizer.get_feature_names()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model for Software:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for All_Beauty:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Prime_Pantry:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Gift_Cards:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Industrial_and_Scientific:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Arts_Crafts_and_Sewing:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Appliances:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Video_Games:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Luxury_Beauty:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for AMAZON_FASHION:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n",
      "\n",
      "Topics in LDA model for Office_Products:\n",
      "Topic #0: great product fast good super deal original add wonderful ship\n",
      "Topic #1: work just used don want card look didn buy like\n",
      "Topic #2: time need just way long don make plastic tape like\n",
      "Topic #3: use easy amazon used home product better come problem light\n",
      "Topic #4: nice like really fine use little write just pencil desk\n",
      "Topic #5: good quality price colors set cartridges best box different exactly\n",
      "Topic #6: love perfect buy recommend definitely highly book size especially sturdy\n",
      "Topic #7: printer ink paper pen color print black cartridge smooth blue\n",
      "Topic #8: pens office year expensive cost worth school machine old use\n",
      "Topic #9: works great phone excellent item ok perfectly useful power stuff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Performing LDA on Vectorized set\"\"\"\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=10,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "\n",
    "for cat in range(len(category)):\n",
    "    #lda_fit = lda.fit(ct[cat])\n",
    "    print(\"\\nTopics in LDA model for %s:\" %(category[cat]))\n",
    "    tf_feature_names = ct_vectorizer.get_feature_names()\n",
    "    print_top_words(lda_fit, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068055"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for j in data for i in j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessery modules \n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "# Reads data files\n",
    "#df = load.loadDF()\n",
    "\n",
    "\n",
    "\n",
    "stopwords = set(STOPWORDS) \n",
    "\n",
    "\n",
    "# iterate through the csv file \n",
    "for val in data: \n",
    "    comment_words = '' \n",
    "    # typecaste each val to string \n",
    "    val = str(val)\n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "      \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "  \n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) \n",
    "  \n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "  \n",
    "    plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
